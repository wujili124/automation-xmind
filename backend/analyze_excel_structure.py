#!/usr/bin/env python3
"""
è¯¦ç»†åˆ†æã€Šå†’çƒŸç”¨ä¾‹å¯¼å‡ºæ¨¡ç‰ˆ.xlsxã€‹çš„ç»“æ„
é‡ç‚¹åˆ†æè¡¨æ ¼åˆå¹¶ã€èŠ‚ç‚¹æ’åˆ—å’Œè§†è§‰æ•ˆæœ
"""

import pandas as pd
import logging
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def analyze_excel_structure():
    """è¯¦ç»†åˆ†æExcelæ¨¡ç‰ˆçš„ç»“æ„å’Œåˆå¹¶å•å…ƒæ ¼"""
    
    template_path = "../å†’çƒŸç”¨ä¾‹å¯¼å‡ºæ¨¡ç‰ˆ.xlsx"
    
    if not os.path.exists(template_path):
        logger.error(f"âŒ æ¨¡ç‰ˆæ–‡ä»¶ä¸å­˜åœ¨: {template_path}")
        return None
    
    logger.info("ğŸ” å¼€å§‹è¯¦ç»†åˆ†æExcelæ¨¡ç‰ˆç»“æ„...")
    
    try:
        # ä½¿ç”¨openpyxlè¯¦ç»†åˆ†æ
        wb = load_workbook(template_path)
        
        for sheet_name in wb.sheetnames:
            logger.info(f"\nğŸ“‹ åˆ†æå·¥ä½œè¡¨: {sheet_name}")
            ws = wb[sheet_name]
            
            if sheet_name == "å†’çƒŸæµ‹è¯•ç”¨ä¾‹":
                analyze_main_sheet_structure(ws)
            elif sheet_name == "å¯¼å‡ºæ±‡æ€»":
                analyze_summary_sheet_structure(ws)
        
        wb.close()
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
        return None

def analyze_main_sheet_structure(ws):
    """è¯¦ç»†åˆ†æä¸»å·¥ä½œè¡¨çš„ç»“æ„"""
    logger.info("ğŸ¯ åˆ†æå†’çƒŸæµ‹è¯•ç”¨ä¾‹å·¥ä½œè¡¨ç»“æ„...")
    
    # 1. åˆ†æåˆå¹¶å•å…ƒæ ¼
    logger.info("\nğŸ”— åˆå¹¶å•å…ƒæ ¼åˆ†æ:")
    merged_ranges = list(ws.merged_cells.ranges)
    
    if merged_ranges:
        for i, merged_range in enumerate(merged_ranges):
            start_row, start_col = merged_range.min_row, merged_range.min_col
            end_row, end_col = merged_range.max_row, merged_range.max_col
            
            # è·å–åˆå¹¶å•å…ƒæ ¼çš„å€¼
            cell_value = ws.cell(start_row, start_col).value
            
            logger.info(f"   åˆå¹¶{i+1}: {merged_range} = {cell_value}")
            logger.info(f"     èŒƒå›´: è¡Œ{start_row}-{end_row}, åˆ—{start_col}-{end_col}")
            logger.info(f"     å°ºå¯¸: {end_row-start_row+1}è¡Œ x {end_col-start_col+1}åˆ—")
            
            # åˆ†æåˆå¹¶æ¨¡å¼
            if end_row - start_row > 0:
                logger.info(f"     âœ… å‚ç›´åˆå¹¶: è·¨{end_row-start_row+1}è¡Œ")
            if end_col - start_col > 0:
                logger.info(f"     âœ… æ°´å¹³åˆå¹¶: è·¨{end_col-start_col+1}åˆ—")
    else:
        logger.info("   âŒ æ²¡æœ‰å‘ç°åˆå¹¶å•å…ƒæ ¼")
    
    # 2. åˆ†æè¡¨å¤´ç»“æ„
    logger.info("\nğŸ“Š è¡¨å¤´ç»“æ„åˆ†æ:")
    for row in range(1, min(ws.max_row + 1, 6)):  # åˆ†æå‰5è¡Œ
        row_data = []
        for col in range(1, ws.max_column + 1):
            cell_value = ws.cell(row, col).value
            row_data.append(cell_value)
        
        logger.info(f"   ç¬¬{row}è¡Œ: {row_data}")
    
    # 3. åˆ†ææ•°æ®æ’åˆ—æ¨¡å¼
    logger.info("\nğŸ“ˆ æ•°æ®æ’åˆ—æ¨¡å¼åˆ†æ:")
    
    # æŸ¥æ‰¾èŠ‚ç‚¹åˆ—çš„æ¨¡å¼
    node_columns = {}
    for col in range(1, 6):  # å‰5åˆ—é€šå¸¸æ˜¯èŠ‚ç‚¹
        col_letter = get_column_letter(col)
        col_values = []
        
        for row in range(2, ws.max_row + 1):  # ä»ç¬¬2è¡Œå¼€å§‹ï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            cell_value = ws.cell(row, col).value
            if cell_value:
                col_values.append(cell_value)
        
        if col_values:
            node_columns[f"èŠ‚ç‚¹{col}"] = {
                'unique_values': list(set(col_values)),
                'total_values': len(col_values),
                'pattern_analysis': analyze_column_pattern(col_values)
            }
    
    # æ˜¾ç¤ºèŠ‚ç‚¹åˆ†æç»“æœ
    for node_name, info in node_columns.items():
        logger.info(f"   {node_name}:")
        logger.info(f"     å”¯ä¸€å€¼: {info['unique_values']}")
        logger.info(f"     æ€»æ•°æ®: {info['total_values']}")
        logger.info(f"     æ¨¡å¼: {info['pattern_analysis']}")
    
    # 4. åˆ†æå±‚çº§å…³ç³»
    logger.info("\nğŸ—ï¸ å±‚çº§å…³ç³»åˆ†æ:")
    analyze_hierarchical_structure(ws)

def analyze_column_pattern(values):
    """åˆ†æåˆ—çš„æ•°æ®æ¨¡å¼"""
    if not values:
        return "ç©ºåˆ—"
    
    # æ£€æŸ¥é‡å¤æ¨¡å¼
    unique_count = len(set(values))
    total_count = len(values)
    
    if unique_count == 1:
        return f"å•ä¸€å€¼é‡å¤ ({values[0]})"
    elif unique_count == total_count:
        return "æ¯è¡Œå”¯ä¸€å€¼"
    else:
        return f"éƒ¨åˆ†é‡å¤ ({unique_count}/{total_count})"

def analyze_hierarchical_structure(ws):
    """åˆ†æå±‚çº§ç»“æ„å’Œåˆå¹¶é€»è¾‘"""
    
    # æ„å»ºæ•°æ®ç»“æ„
    data_structure = []
    
    for row in range(2, ws.max_row + 1):  # ä»æ•°æ®è¡Œå¼€å§‹
        row_data = {}
        for col in range(1, ws.max_column + 1):
            col_letter = get_column_letter(col)
            cell_value = ws.cell(row, col).value
            
            # è·å–è¡¨å¤´åç§°
            header = ws.cell(1, col).value or f"åˆ—{col}"
            row_data[header] = cell_value
        
        data_structure.append(row_data)
    
    # åˆ†æèŠ‚ç‚¹å±‚çº§å…³ç³»
    logger.info("   èŠ‚ç‚¹å±‚çº§åˆ†æ:")
    
    node_hierarchy = {}
    for row_data in data_structure:
        nodes = []
        for i in range(1, 6):  # èŠ‚ç‚¹1-5
            node_key = f"èŠ‚ç‚¹{i}"
            if node_key in row_data and row_data[node_key]:
                nodes.append(row_data[node_key])
        
        if nodes:
            path = " > ".join(nodes)
            if path not in node_hierarchy:
                node_hierarchy[path] = []
            node_hierarchy[path].append(row_data)
    
    # æ˜¾ç¤ºå±‚çº§å…³ç³»
    for path, rows in node_hierarchy.items():
        logger.info(f"     è·¯å¾„: {path}")
        logger.info(f"       æ•°æ®è¡Œæ•°: {len(rows)}")
        
        # åˆ†æè¿™ä¸ªè·¯å¾„ä¸‹çš„å˜åŒ–
        varying_fields = analyze_varying_fields(rows)
        if varying_fields:
            logger.info(f"       å˜åŒ–å­—æ®µ: {varying_fields}")

def analyze_varying_fields(rows):
    """åˆ†æåœ¨ç›¸åŒè·¯å¾„ä¸‹å“ªäº›å­—æ®µæœ‰å˜åŒ–"""
    if len(rows) <= 1:
        return []
    
    varying_fields = []
    all_keys = rows[0].keys()
    
    for key in all_keys:
        values = [row.get(key) for row in rows]
        unique_values = set(v for v in values if v is not None)
        
        if len(unique_values) > 1:
            varying_fields.append(f"{key}({len(unique_values)}ç§)")
    
    return varying_fields

def analyze_summary_sheet_structure(ws):
    """åˆ†ææ±‡æ€»å·¥ä½œè¡¨ç»“æ„"""
    logger.info("ğŸ“‹ åˆ†æå¯¼å‡ºæ±‡æ€»å·¥ä½œè¡¨ç»“æ„...")
    
    # ç®€å•åˆ†ææ±‡æ€»è¡¨
    for row in range(1, ws.max_row + 1):
        col1_value = ws.cell(row, 1).value
        col2_value = ws.cell(row, 2).value
        logger.info(f"   ç¬¬{row}è¡Œ: {col1_value} | {col2_value}")

def generate_structure_recommendations():
    """ç”Ÿæˆç»“æ„æ”¹è¿›å»ºè®®"""
    logger.info("\nğŸ’¡ ç»“æ„æ”¹è¿›å»ºè®®:")
    
    recommendations = [
        "1. è¡¨æ ¼åˆå¹¶ç­–ç•¥:",
        "   - ç›¸åŒèŠ‚ç‚¹1çš„è¡Œåº”è¯¥å‚ç›´åˆå¹¶",
        "   - ç›¸åŒèŠ‚ç‚¹1+èŠ‚ç‚¹2çš„ç»„åˆåº”è¯¥åˆå¹¶",
        "   - ä»¥æ­¤ç±»æ¨åˆ°èŠ‚ç‚¹5",
        "",
        "2. è§†è§‰å±‚çº§æ•ˆæœ:",
        "   - ä½¿ç”¨ä¸åŒçš„èƒŒæ™¯è‰²åŒºåˆ†å±‚çº§",
        "   - èŠ‚ç‚¹1ä½¿ç”¨æ·±è‰²èƒŒæ™¯",
        "   - èŠ‚ç‚¹2ä½¿ç”¨ä¸­ç­‰èƒŒæ™¯",
        "   - èŠ‚ç‚¹3-5ä½¿ç”¨æµ…è‰²èƒŒæ™¯",
        "",
        "3. åˆå¹¶å•å…ƒæ ¼å®ç°:",
        "   - ä½¿ç”¨openpyxlçš„merge_cellsåŠŸèƒ½",
        "   - æŒ‰å±‚çº§é€’å½’åˆå¹¶ç›¸åŒå€¼çš„å•å…ƒæ ¼",
        "   - ä¿æŒæ•°æ®å®Œæ•´æ€§",
        "",
        "4. æ’åºå’Œåˆ†ç»„:",
        "   - æŒ‰èŠ‚ç‚¹1åˆ†ç»„",
        "   - èŠ‚ç‚¹1å†…æŒ‰èŠ‚ç‚¹2åˆ†ç»„",
        "   - ä»¥æ­¤ç±»æ¨å®ç°å±‚çº§æ’åº"
    ]
    
    for recommendation in recommendations:
        logger.info(recommendation)

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹Excelæ¨¡ç‰ˆç»“æ„è¯¦ç»†åˆ†æ...")
    
    analyze_excel_structure()
    generate_structure_recommendations()
    
    logger.info("\nâœ… åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main() 